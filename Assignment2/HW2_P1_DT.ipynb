{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üå≥ Homework: Programming Tree-Based Models\n",
    "\n",
    "## üí° Core Idea & Pipeline\n",
    "\n",
    "This notebook provides a complete, hands-on pipeline for building, evaluating, and optimizing a decision tree classifier. The goal is to move beyond just calling `.fit()` and `.predict()` and to deeply understand the *process* of model tuning.\n",
    "\n",
    "We will use the \"Adult\" (Census) dataset, a classic classification task to predict whether an individual's income is greater than $50K/year.\n",
    "\n",
    "**Our pipeline will cover:**\n",
    "\n",
    "1.  **Environment Setup:** Downloading the data and setting up reproducible hyperparameters.\n",
    "2.  **Data Preprocessing:** This is a crucial and realistic step. We will load messy, real-world data and transform it into a clean, numerical format suitable for `scikit-learn`. This includes:\n",
    "      * Handling missing values (marked as `?`).\n",
    "      * Cleaning inconsistent data (the test set has artifacts).\n",
    "      * Performing **One-Hot Encoding** for categorical features.\n",
    "      * Splitting data into **three** distinct sets: **Train, Validation, and Test**.\n",
    "3.  **Baseline Modeling:** We'll build a standard, unpruned decision tree to establish a \"baseline\" performance. We expect this model to be complex and to **overfit**.\n",
    "4.  **Model Optimization (Pruning):** We'll use **Cost-Complexity Pruning (CCP)**, a robust method for finding a simpler, more generalizable tree. This is the core of the exercise:\n",
    "      * We will use the **Training set** to *build* the trees.\n",
    "      * We will use the **Validation set** to *select the best pruning hyperparameter (`ccp_alpha`)*.\n",
    "      * We will (finally) use the **Test set** to *report the final, unbiased performance* of our chosen model.\n",
    "5.  **Advanced Exploration:** We will investigate the `max_features` hyperparameter, which forms the basis of the **Random Forest** algorithm, to see how feature randomization affects model performance and structure.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú®**Your Tasks:**\n",
    "You are required to complete **three coding problems** (each worth **5 or 10 points**) indicated by the marker:\n",
    "\n",
    "```python\n",
    "######################################\n",
    "## WRITE YOUR CODE HERE (10 Points) ##\n",
    "######################################\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Downloading the Training and Test Datasets\n",
    "\n",
    "You can obtain the **Adult** dataset files ‚Äî `adult.data` (training set) and `adult.test` (test set) ‚Äî using one of the following methods:\n",
    "\n",
    "1. **Direct download** from the URLs provided below.\n",
    "2. **Download from Blackboard**, located in the directory for **HW2**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Data source URLs from the UCI Machine Learning Repository\n",
    "urls = {\n",
    "    \"adult.data\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    \"adult.test\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
    "}\n",
    "\n",
    "# Function to download the file if it doesn't exist\n",
    "def download_if_missing(filename, url):\n",
    "    \"\"\"\n",
    "    Checks for a local file and downloads it from a URL if missing.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): The local path to save the file.\n",
    "        url (str): The remote URL to download from.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"üì• Downloading: {filename} ...\")\n",
    "        # Use urllib to retrieve the file from the web\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(f\"‚úÖ Saved: {filename}\")\n",
    "    else:\n",
    "        print(f\"‚úî File already exists: {filename}\")\n",
    "\n",
    "# Run download for both files\n",
    "for fname, link in urls.items():\n",
    "    download_if_missing(fname, link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:Imports & Experiment Configuration\n",
    "\n",
    "**Motivation:** This cell acts as our central control panel. We import all necessary libraries (`pandas` for data manipulation, `sklearn` for modeling, `matplotlib` for plotting) and define global constants.\n",
    "\n",
    "Setting constants like `RANDOM_SEED` is **essential for reproducibility**. It ensures that every time we run this script, the \"random\" operations (like sampling and model training) will produce the exact same results. `N_TRAIN_SAMPLES` is set to a small number to speed up our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## First, we need to install all the packages using tsinghua source\n",
    "### we use uv to install the packages, as uv enables to speed up the installation of the packages\n",
    "!pip install uv -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!uv pip install pandas numpy scikit-learn matplotlib -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Hyperparameters & Global Settings ---\n",
    "\n",
    "# Subsample size for training and testing.\n",
    "# The full dataset has >30,000 rows, which can be slow to process.\n",
    "# We use a small, fixed subset for fast experimentation and reproducibility.\n",
    "N_TRAIN_SAMPLES = 500\n",
    "N_TEST_SAMPLES = 50\n",
    "\n",
    "# A single random seed for all steps ensures reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Proportion of the training data to hold out for validation\n",
    "VAL_SPLIT_SIZE = 0.25\n",
    "\n",
    "# Column names for the Adult dataset (not provided in the .data file)\n",
    "COLUMN_NAMES = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "\n",
    "# Local file paths\n",
    "LOCAL_TRAIN_FILE = 'adult.data'\n",
    "LOCAL_TEST_FILE = 'adult.test'\n",
    "\n",
    "\n",
    "print(f\"--- Experiment Settings ---\")\n",
    "print(f\"Random Seed: {RANDOM_SEED}\")\n",
    "print(f\"Training Samples (Subsampled): {N_TRAIN_SAMPLES}\")\n",
    "print(f\"Test Samples (Subsampled): {N_TEST_SAMPLES}\")\n",
    "print(\"-\" * 30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Data Loading & Preprocessing\n",
    "\n",
    "**Motivation:** This is the data engineering phase. Real-world data is never clean. We must load the data and transform it into a numerical feature matrix `X` and a target vector `y`.\n",
    "\n",
    "**Key Steps:**\n",
    "\n",
    "1.  **Load:** Read the CSVs using `pandas`. We must specify `sep=', '`, `na_values=' ?'`, and `skiprows=1` (for the test file) to handle the dataset's quirks.\n",
    "2.  **Sample:** Use `.sample()` to grab a small, random subset, using our `RANDOM_SEED`.\n",
    "3.  **Combine:** We **temporarily combine** the train and test sets. This is a critical step to ensure that `pd.get_dummies` (One-Hot Encoding) sees all possible categories from *both* sets, preventing a \"mismatched columns\" error later.\n",
    "4.  **Clean:**\n",
    "      * `dropna()`: A simple strategy to handle missing values (marked as `?`).\n",
    "      * `.str.replace('.', ...)`: The test set's target variable has an extra period (e.g., `<=50K.`). We must remove it.\n",
    "      * `.map(...)`: Convert the string target (`<=50K`) into a binary integer (`0` or `1`).\n",
    "5.  **Encode:** Use `pd.get_dummies` to convert categorical columns (like 'workclass', 'occupation') into many binary (0/1) columns. `drop_first=True` is used to prevent perfect multicollinearity.\n",
    "6.  **Split:** We split the data back into `train` and `test`. Then, we split the `train` data *again* into `X_train` and `X_val`. This gives us our three distinct sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Loading & Preprocessing ---\n",
    "\n",
    "print(\"--- Step 1: Data Loading & Preprocessing ---\")\n",
    "\n",
    "# --- 2.1 Check for local files ---\n",
    "# (Ensuring Cell 1 was run)\n",
    "if not os.path.exists(LOCAL_TRAIN_FILE):\n",
    "    print(f\"Local file {LOCAL_TRAIN_FILE} not found. Please re-run Cell 1 to download.\")\n",
    "    raise FileNotFoundError(f\"Local file {LOCAL_TRAIN_FILE} not found.\")\n",
    "else:\n",
    "    print(f\"Found local file: {LOCAL_TRAIN_FILE}\")\n",
    "\n",
    "if not os.path.exists(LOCAL_TEST_FILE):\n",
    "    print(f\"Local file {LOCAL_TEST_FILE} not found. Please re-run Cell 1 to download.\")\n",
    "    raise FileNotFoundError(f\"Local file {LOCAL_TEST_FILE} not found.\")\n",
    "else:\n",
    "    print(f\"Found local file: {LOCAL_TEST_FILE}\")\n",
    "\n",
    "# --- 2.2 Load from local files ---\n",
    "print(\"\\nLoading data from local files...\")\n",
    "# Note the specific parameters needed for this dataset\n",
    "df_train_raw = pd.read_csv(\n",
    "    LOCAL_TRAIN_FILE,  # <-- Read from the local file\n",
    "    names=COLUMN_NAMES,\n",
    "    sep=', ',          # The separator is a comma *followed by a space*\n",
    "    na_values=' ?',     # Missing values are marked with ' ?'\n",
    "    engine='python'    # 'python' engine handles the 'sep' correctly\n",
    ")\n",
    "df_test_raw = pd.read_csv(\n",
    "    LOCAL_TEST_FILE,   # <-- Read from the local file\n",
    "    names=COLUMN_NAMES,\n",
    "    sep=', ',\n",
    "    na_values=' ?',\n",
    "    skiprows=1,        # The test file has an extra header row\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "# Randomly sample the data as specified\n",
    "df_train = df_train_raw.sample(n=N_TRAIN_SAMPLES, random_state=RANDOM_SEED)\n",
    "df_test = df_test_raw.sample(n=N_TEST_SAMPLES, random_state=RANDOM_SEED)\n",
    "\n",
    "# To ensure consistent One-Hot Encoding, we combine train and test\n",
    "# We add a 'set' marker to split them back up later\n",
    "df_train['set'] = 'train'\n",
    "df_test['set'] = 'test'\n",
    "df_combined = pd.concat([df_train, df_test])\n",
    "\n",
    "\n",
    "## View the raw-ish data\n",
    "example_train = df_train.head(5)\n",
    "example_test = df_test.head(5)\n",
    "\n",
    "print(\"Training data example:\")\n",
    "example_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTest data example:\")\n",
    "example_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2.3 Preprocessing Pipeline ---\n",
    "# 1. Filter NA values (as requested)\n",
    "df_processed = df_combined.dropna()\n",
    "\n",
    "# 2. Clean the target variable 'income'\n",
    "#    The test set has an extra '.' (e.g., ' <=50K.'), which we must remove\n",
    "df_processed['income'] = df_processed['income'].str.replace('.', '', regex=False)\n",
    "#    Map the 'income' string to a binary 0/1 integer\n",
    "df_processed['income'] = df_processed['income'].map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "# 3. Convert categorical features to numeric (One-Hot Encoding)\n",
    "#    Separate X (features) and y (target)\n",
    "y = df_processed['income']\n",
    "set_marker = df_processed['set']\n",
    "X = df_processed.drop(['income', 'set'], axis=1)\n",
    "\n",
    "#    Use pd.get_dummies for One-Hot Encoding\n",
    "#    drop_first=True helps avoid multicollinearity (dummy variable trap)\n",
    "X_processed = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 4. Re-split the data back into train, val, and test sets\n",
    "X_processed['set'] = set_marker\n",
    "X_processed['income'] = y\n",
    "\n",
    "# Split back into processed train/test sets\n",
    "df_train_val_processed = X_processed[X_processed['set'] == 'train']\n",
    "df_test_processed = X_processed[X_processed['set'] == 'test']\n",
    "\n",
    "# Prepare final X and y for modeling\n",
    "X_test = df_test_processed.drop(['income', 'set'], axis=1)\n",
    "y_test = df_test_processed['income']\n",
    "\n",
    "X_train_val = df_train_val_processed.drop(['income', 'set'], axis=1)\n",
    "y_train_val = df_train_val_processed['income']\n",
    "\n",
    "# Split the processed training data into a (smaller) train set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    test_size=VAL_SPLIT_SIZE,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nOriginal train data {len(df_train_raw)} -> Sampled {len(df_train)} -> Cleaned {len(df_train_val_processed)}\")\n",
    "print(f\"Original test data {len(df_test_raw)} -> Sampled {len(df_test)} -> Cleaned {len(df_test_processed)}\")\n",
    "print(f\"Final Training Set (X_train): {X_train.shape}\")\n",
    "print(f\"Final Validation Set (X_val): {X_val.shape}\")\n",
    "print(f\"Final Test Set (X_test): {X_test.shape}\")\n",
    "print(\"Preprocessing complete.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: Building the Baseline Classifier\n",
    "\n",
    "**Motivation:**\n",
    "In this step, we construct our initial model, referred to as the *baseline classifier*. This decision tree is trained to its maximum possible depth (`max_depth=None` by default). As a result, the model is expected to exhibit high complexity, achieving perfect or near-perfect performance on the training dataset. However, such behavior typically indicates **overfitting**, where the model memorizes noise and idiosyncrasies in the training data, leading to poor generalization on unseen test data. The resulting test accuracy of this baseline model will serve as a benchmark for subsequent model improvements.\n",
    "\n",
    "**Note:**\n",
    "For a detailed explanation of all available parameters and to explore different parameter combinations, please refer to the [DecisionTreeClassifier documentation in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Step 2: Build Base Classifier ---\n",
    "\n",
    "print(\"--- Step 2: Base Classifier (Unpruned) ---\")\n",
    "\n",
    "\n",
    "######################################\n",
    "## WRITE YOUR CODE HERE (5 Points) ##\n",
    "######################################\n",
    "# üéØ Task:\n",
    "# Build and evaluate your **baseline Decision Tree classifier**.\n",
    "#\n",
    "# Steps to follow:\n",
    "# 1Ô∏è‚É£ Initialize a DecisionTreeClassifier instance.\n",
    "#     - Use `criterion='entropy'` (this tells the tree to use *Information Gain*).\n",
    "#     - Set `random_state=RANDOM_SEED` to make your results reproducible.\n",
    "#\n",
    "# 2Ô∏è‚É£ Train the model using the *training set*.\n",
    "#     - Hint: look for the `.fit()` method in the sklearn documentation.\n",
    "#\n",
    "# 3Ô∏è‚É£ Generate predictions on the *test set*.\n",
    "#     - Hint: check out the `.predict()` method.\n",
    "#\n",
    "# üß≠ Reference:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "#\n",
    "# ‚úÖ Expected output:\n",
    "# After training and prediction, you should have:\n",
    "#   - A trained model object (clf_base)\n",
    "#   - A vector of predicted labels (y_pred_base)\n",
    "#\n",
    "# üí° (Tip: You do NOT need to manually tune parameters yet‚Äîjust use defaults!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base Model (Unpruned) Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_base))\n",
    "print(f\"Base Model (Unpruned) Depth: {clf_base.get_depth()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5: Pruning with Cost-Complexity Pruning (CCP)\n",
    "\n",
    "**Motivation:** Our baseline model maybe overfit. Pruning is a technique to simplify the tree by \"cutting off\" the weakest branches. This makes the model less complex and helps it generalize better.\n",
    "\n",
    "**CCP Pipeline:**\n",
    "\n",
    "1.  **Get Path:** We use `cost_complexity_pruning_path` to generate a list of all possible \"pruning levels,\" defined by the hyperparameter `ccp_alpha`. A higher `alpha` results in more pruning (a smaller tree).\n",
    "2.  **Validate Alphas:** We loop through each `alpha` value. For each one, we train a *new* pruned tree on the `X_train` data.\n",
    "3.  **Score:** We score that pruned tree on the **validation set (`X_val`)**. This is the most important step\\! We are using the validation set to see which `alpha` gives the best performance on data it *wasn't* trained on.\n",
    "4.  **Find Best:** We use `np.argmax` to find the `alpha` that produced the highest validation score.\n",
    "5.  **Retrain Final Model:** Now that we have our \"winning\" `alpha`, we train *one final model*. This time, we use the best `alpha` and train on the **entire `X_train_val` set**. This lets our final model learn from all available training and validation data before its final test.\n",
    "6.  **Final Evaluation:** We evaluate this new, pruned, retrained model on the `X_test` set. We hope to see a simpler tree (lower depth) and a *higher* test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Step 3: Pruning using Validation Set (Cost-Complexity Pruning) ---\n",
    "\n",
    "print(\"--- Step 3: Cost-Complexity Pruning (CCP) ---\")\n",
    "\n",
    "# Get the list of effective alphas and impurities\n",
    "# This path is generated using *only* the training data\n",
    "path = clf_base.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# We remove the last alpha, which corresponds to a tree with only one node (the root)\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "clfs = []         # To store pruned trees\n",
    "val_scores = []   # To store scores on the validation set\n",
    "\n",
    "print(f\"Validating on {len(ccp_alphas)} different alpha values...\")\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    # Create a new tree instance with the specified ccp_alpha\n",
    "    clf_pruned = DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        random_state=RANDOM_SEED,\n",
    "        ccp_alpha=ccp_alpha  # This is the pruning parameter\n",
    "    )\n",
    "    \n",
    "    # Fit the pruned tree *only* on the training data\n",
    "    clf_pruned.fit(X_train, y_train)\n",
    "    \n",
    "    # Score the tree on the *validation* data\n",
    "    val_score = clf_pruned.score(X_val, y_val)\n",
    "    \n",
    "    clfs.append(clf_pruned)\n",
    "    val_scores.append(val_score)\n",
    "\n",
    "######################################\n",
    "## WRITE YOUR CODE HERE (10 Points) ##\n",
    "######################################\n",
    "# üéØ Task:\n",
    "# Identify the pruning parameter (`ccp_alpha`) that gives the best performance on the validation set.\n",
    "#\n",
    "# Hints:\n",
    "# 1Ô∏è‚É£ You have a list/array of validation scores for different alpha values (`val_scores`).\n",
    "# 2Ô∏è‚É£ You also have a corresponding list/array of alpha values (`ccp_alphas`).\n",
    "# 3Ô∏è‚É£ Your goal is to find the alpha that **maximizes the validation score**.\n",
    "# 4Ô∏è‚É£ Useful numpy functions:\n",
    "#     - `np.argmax()` returns the index of the maximum value in an array.\n",
    "#     - You can use this index to look up the corresponding alpha in `ccp_alphas`.\n",
    "#\n",
    "# ‚úÖ Expected output:\n",
    "# - best_alpha_index: index of the alpha with the highest validation score\n",
    "# - best_ccp_alpha: the alpha value itself\n",
    "\n",
    "\n",
    "print(f\"Best ccp_alpha found on validation set: {best_ccp_alpha:.6f}\")\n",
    "\n",
    "# Now, train the *final* model using the best alpha on the\n",
    "# *combined* training + validation data (X_train_val, y_train_val)\n",
    "clf_final_pruned = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    random_state=RANDOM_SEED,\n",
    "    ccp_alpha=best_ccp_alpha # Use the best alpha we found\n",
    ")\n",
    "clf_final_pruned.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Evaluate the final pruned model on the test set\n",
    "y_pred_pruned = clf_final_pruned.predict(X_test)\n",
    "print(\"Pruned Model Performance on Test Set:\")\n",
    "print(classification_report(y_test, y_pred_pruned))\n",
    "\n",
    "\n",
    "print(\"\\n--- Pruning Comparison ---\")\n",
    "print(f\"Unpruned Model Depth: {clf_base.get_depth()} | Test Accuracy: {accuracy_score(y_test, y_pred_base):.4f}\")\n",
    "print(f\"Pruned Model Depth: {clf_final_pruned.get_depth()} | Test Accuracy: {accuracy_score(y_test, y_pred_pruned):.4f}\")\n",
    "print(\"Pruning typically reduces depth, combating overfitting and often improving or maintaining test accuracy.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6: Exploration of `max_features`\n",
    "\n",
    "**Motivation:** This is an advanced exploration. A standard decision tree (Model A) considers *all* available features at *every* split to find the best one.\n",
    "\n",
    "What if we introduced more randomness? Model B will only consider a *random subset* of `k` features at each split (`max_features=k`). This is the core idea that makes **Random Forests** so powerful. By forcing the tree to use different features, we create many different, de-correlated trees, which (when averaged) are much more robust.\n",
    "\n",
    "Here, we explore how `max_features` affects the accuracy and depth of a *single* tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Extended Experiment: Impact of max_features ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"\\n--- Step 4: max_features Trend Experiment ---\")\n",
    "\n",
    "# Get the total number of features after one-hot encoding\n",
    "m_features = X_train_val.shape[1]\n",
    "\n",
    "# Create a range of 'k' values to test, from 1 to m_features\n",
    "feature_range = np.unique(\n",
    "    np.linspace(1, m_features, num=15, dtype=int)\n",
    ")\n",
    "\n",
    "acc_A_list = []  # Model A: Standard Tree (all features)\n",
    "acc_B_list = []  # Model B: Random Subset Tree\n",
    "depth_A_list = []\n",
    "depth_B_list = []\n",
    "\n",
    "print(f\"Testing max_features from 1 to {m_features}...\")\n",
    "\n",
    "for k in feature_range:\n",
    "    ######################################\n",
    "    ## WRITE YOUR CODE HERE (10 Points) ##\n",
    "    ######################################\n",
    "    # üéØ Task:\n",
    "    # Implement two types of decision tree classifiers for comparison:\n",
    "    #\n",
    "    # 1Ô∏è‚É£ Model A(clf_A) (Standard Information Gain using all features)\n",
    "    #    - Initialize a DecisionTreeClassifier.\n",
    "    #    - Use `criterion='entropy'`.\n",
    "    #    - Ensure all features are considered at each split.\n",
    "    #    - Use `random_state=RANDOM_SEED` for reproducibility.\n",
    "    #    - Hint: refer to the sklearn docs for DecisionTreeClassifier parameters:\n",
    "    #      https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "    #\n",
    "    # 2Ô∏è‚É£ Model B(clf_B) (Random Feature Subset at each split)\n",
    "    #    - Initialize a DecisionTreeClassifier.\n",
    "    #    - Use `criterion='entropy'`.\n",
    "    #    - Randomly consider `k` features at each split.\n",
    "    #    - Keep `random_state=RANDOM_SEED`.\n",
    "\n",
    "\n",
    "    # We train on the full train+val set for this experiment\n",
    "    clf_A.fit(X_train_val, y_train_val)\n",
    "    acc_A = clf_A.score(X_test, y_test)\n",
    "    acc_A_list.append(acc_A)\n",
    "    depth_A_list.append(clf_A.get_depth())\n",
    "\n",
    "    # Train model B\n",
    "    clf_B.fit(X_train_val, y_train_val)\n",
    "    acc_B = clf_B.score(X_test, y_test)\n",
    "    acc_B_list.append(acc_B)\n",
    "    depth_B_list.append(clf_B.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Accuracy Trend ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(feature_range, acc_B_list, marker='o', label='Random Feature Model (max_features=k)')\n",
    "# Note: Model A's accuracy is the same for all k, so we just plot the last value\n",
    "plt.axhline(y=acc_A_list[-1], color='r', linestyle='--', label='Standard Model (max_features=None)')\n",
    "plt.title(\"Model Accuracy vs. max_features\")\n",
    "plt.xlabel(\"max_features (k)\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Optional: Plot Depth Trend ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(feature_range, depth_B_list, marker='s', label='Random Feature Model (Depth)')\n",
    "plt.axhline(y=depth_A_list[-1], color='orange', linestyle='--', label='Standard Model (Depth)')\n",
    "plt.title(\"Model Depth vs. max_features\")\n",
    "plt.xlabel(\"max_features (k)\")\n",
    "plt.ylabel(\"Tree Depth\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
