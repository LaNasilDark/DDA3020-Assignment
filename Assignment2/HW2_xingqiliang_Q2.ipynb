{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8e7144",
   "metadata": {},
   "source": [
    "# Assignment 2 - 2.2: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61545f7d",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "In this question, you will implement a CNN model and train it on Fasion-MNIST, which is focusing on image classification. The model structure is similar with that in Written Problem 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85544b6b",
   "metadata": {},
   "source": [
    "### Dataset Introduction\n",
    "\n",
    "First it's important to have an overall knowledge of this dataset. The dataset is called **Fashion-MNIST**, a member of the MNIST family. This dataset is an image classification task with ten categories, all of which are items from our daily lives. It consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image. It means that we can use 784 numbers (in the range of 0~255) to represent one image. More details can be found in https://github.com/zalandoresearch/fashion-mnist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a32ef2",
   "metadata": {},
   "source": [
    "After downloading the data directory from BB, put this notebook file at the same position as \"data\". And this block of code will help to load the data, including basic preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52ac56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_mnist(path, kind, subset=None):\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz'%kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz'%kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    if subset is not None:\n",
    "        selected_images, selected_labels = [], []\n",
    "        for label in range(10):\n",
    "            indices = np.where(labels == label)[0]\n",
    "            selected_indices = np.random.choice(indices, subset, replace=False)\n",
    "            selected_images.append(images[selected_indices])\n",
    "            selected_labels.append(labels[selected_indices])\n",
    "        images = np.concatenate(selected_images, axis=0)\n",
    "        labels = np.concatenate(selected_labels, axis=0)\n",
    "\n",
    "        paired = list(zip(images, labels))\n",
    "        random.shuffle(paired)\n",
    "        images, labels = zip(*paired)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "X_train, y_train = load_mnist('./P2_data/', kind='train')\n",
    "X_test, y_test = load_mnist('./P2_data/', kind='t10k')\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668167c",
   "metadata": {},
   "source": [
    "This block will randomly select one sample from the dataset, displaying the label index, label name, and the corresponding image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c9205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label index of this image is: 8\n",
      "The label name of this graph is: Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "idx = random.choice(range(0,len(X_test)))\n",
    "print(f\"The label index of this image is: {y_test[idx]}\")\n",
    "print(f\"The label name of this graph is: {label_names[y_test[idx]]}\")\n",
    "\n",
    "plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b0c6a",
   "metadata": {},
   "source": [
    "Now we are supposed to build a simple CNN model to train on the data above and test it using the test set. Here we will use PyTorch for implementation. First we can get familiar with the torch by https://docs.pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html. We can install it by running `pip install torch` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633e09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f9240",
   "metadata": {},
   "source": [
    "Recall that the CNN structure is defined as:\n",
    "\n",
    "Conv3(16) + Maxpool2 + Conv5(24) + Maxpool2 + FC10\n",
    "\n",
    "where\n",
    "\n",
    "- Conv3(16): 16 filters with each size 3\\*3\\*D, where D is the depth of the activation volume at the previous layer, stride = 1, padding = 1;\n",
    "- Conv5(24): 24 filters with each size 5\\*5\\*D, where D is the depth of the activation volume at the previous layer, stride = 1, padding = 2;\n",
    "- Maxpool2: 2*2 filter, stride = 2, padding = 0;\n",
    "- FC10: A fully-connected layer with 10 output neurons.\n",
    "\n",
    "Here you need to first define each layer in the _\\_\\_init\\_\\__ function and then connect them in order in the _forward_ function. Remember to write the code between \"Begin of your code\" and \"End of your code\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5410de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1176, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        ###############################################################################\n",
    "        # Begin of your code\n",
    "\n",
    "        # Conv3(16): 16 filters, 3x3 kernel, stride=1, padding=1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # Maxpool2: 2x2 filter, stride=2, padding=0\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Conv5(24): 24 filters, 5x5 kernel, stride=1, padding=2\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=5, stride=1, padding=2)\n",
    "        # Maxpool2: 2x2 filter, stride=2, padding=0\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # FC10: Fully connected layer with 10 output neurons\n",
    "        # After two maxpool layers: 28 -> 14 -> 7\n",
    "        self.fc = nn.Linear(24 * 7 * 7, 10)\n",
    "\n",
    "        # End of your code\n",
    "        ###############################################################################\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ###############################################################################\n",
    "        # Begin of your code\n",
    "\n",
    "        # Conv3(16) + ReLU\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # Maxpool2\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Conv5(24) + ReLU\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # Maxpool2\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten the tensor for fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # FC10\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # End of your code\n",
    "        ###############################################################################\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e882d",
   "metadata": {},
   "source": [
    "Then we can train our model with batch_size=64, learning_rate=0.001, and total_epoch=10. Feel free to modify these hyperparameters if you think it will be better. If you use CPU, it will take several minute to complete the training process. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5e30ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:15,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5165, Train Accuracy: 81.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:12,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.3401, Train Accuracy: 87.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.2994, Train Accuracy: 89.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:09,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.2745, Train Accuracy: 90.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.2542, Train Accuracy: 90.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:09<00:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.2410, Train Accuracy: 91.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:10<00:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.2282, Train Accuracy: 91.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:12<00:03,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.2169, Train Accuracy: 92.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:13<00:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.2074, Train Accuracy: 92.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.1995, Train Accuracy: 92.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).permute(0, 3, 1, 2)\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "X_test_tensor = torch.from_numpy(X_test).permute(0, 3, 1, 2)\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "num_epochs = 10\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ece54",
   "metadata": {},
   "source": [
    "After training, the final step is to verify if our model does well in this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c350a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 90.77%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'\\nTest Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d070f2",
   "metadata": {},
   "source": [
    "Note that if you obtain a good test score (larger than 80%), you will get full marks in this problem. The test score is usually around 90% for this CNN structure and training configuration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
