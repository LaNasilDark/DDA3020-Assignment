{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "import warnings\n",
    "from scipy.optimize import minimize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGB = True\n",
    "except ImportError:\n",
    "    HAS_LGB = False\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "MIN_INVESTMENT = 0\n",
    "MAX_INVESTMENT = 2\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    DATA_DIR = '/kaggle/input/hull-tactical-market-prediction'\n",
    "else:\n",
    "    DATA_DIR = '.'\n",
    "\n",
    "# ============================================\n",
    "# EVALUATION METRIC\n",
    "# ============================================\n",
    "def calculate_sharpe_ratio(positions, forward_returns, risk_free_rate):\n",
    "    positions = np.array(positions)\n",
    "    forward_returns = np.array(forward_returns)\n",
    "    risk_free_rate = np.array(risk_free_rate)\n",
    "    \n",
    "    strategy_returns = risk_free_rate * (1 - positions) + positions * forward_returns\n",
    "    strategy_excess_returns = strategy_returns - risk_free_rate\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    n = len(positions)\n",
    "    strategy_mean_excess_return = strategy_excess_cumulative ** (1 / n) - 1\n",
    "    strategy_std = strategy_returns.std()\n",
    "    \n",
    "    if strategy_std == 0:\n",
    "        return -999\n",
    "    \n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "    strategy_volatility = strategy_std * np.sqrt(TRADING_DAYS_PER_YEAR) * 100\n",
    "    \n",
    "    market_excess_returns = forward_returns - risk_free_rate\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = market_excess_cumulative ** (1 / n) - 1\n",
    "    market_std = forward_returns.std()\n",
    "    market_volatility = market_std * np.sqrt(TRADING_DAYS_PER_YEAR) * 100\n",
    "    \n",
    "    if market_volatility == 0:\n",
    "        return -999\n",
    "    \n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2)\n",
    "    vol_penalty = 1 + excess_vol\n",
    "    \n",
    "    return_gap = max(0, (market_mean_excess_return - strategy_mean_excess_return) * 100 * TRADING_DAYS_PER_YEAR)\n",
    "    return_penalty = 1 + (return_gap ** 2) / 100\n",
    "    \n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    return adjusted_sharpe\n",
    "\n",
    "# ============================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================\n",
    "class FeatureEngineer:\n",
    "    def __init__(self):\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "        self.scaler = RobustScaler()\n",
    "        self.feature_cols = None\n",
    "        self.all_feature_cols = None\n",
    "        \n",
    "    def _add_engineered_features(self, df):\n",
    "        df = df.copy()\n",
    "        m_cols = [c for c in df.columns if c.startswith('M')]\n",
    "        v_cols = [c for c in df.columns if c.startswith('V')]\n",
    "        s_cols = [c for c in df.columns if c.startswith('S')]\n",
    "        e_cols = [c for c in df.columns if c.startswith('E')]\n",
    "        \n",
    "        for prefix, cols in [('M', m_cols), ('V', v_cols), ('S', s_cols), ('E', e_cols)]:\n",
    "            if cols:\n",
    "                df[f'{prefix}_mean'] = df[cols].mean(axis=1)\n",
    "                df[f'{prefix}_std'] = df[cols].std(axis=1)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def fit(self, df, feature_cols):\n",
    "        self.feature_cols = feature_cols\n",
    "        df_eng = self._add_engineered_features(df)\n",
    "        eng_cols = [c for c in df_eng.columns if c.endswith(('_mean', '_std'))]\n",
    "        self.all_feature_cols = feature_cols + [c for c in eng_cols if c not in feature_cols]\n",
    "        \n",
    "        X = df_eng[self.all_feature_cols].values\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "        self.scaler.fit(X_imputed)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df_eng = self._add_engineered_features(df)\n",
    "        X = df_eng[self.all_feature_cols].values\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "        X_scaled = self.scaler.transform(X_imputed)\n",
    "        return X_scaled\n",
    "    \n",
    "    def fit_transform(self, df, feature_cols):\n",
    "        self.fit(df, feature_cols)\n",
    "        return self.transform(df)\n",
    "\n",
    "# ============================================\n",
    "# STRATEGY\n",
    "# ============================================\n",
    "class RobustStrategy:\n",
    "    def __init__(self):\n",
    "        self.sensitivity = 1500\n",
    "        self.max_weight = 1.3\n",
    "        self.min_weight = 0.5\n",
    "        \n",
    "    def predict_to_weight(self, predictions):\n",
    "        predictions = np.array(predictions)\n",
    "        scaled = predictions * self.sensitivity\n",
    "        sigmoid_output = 1 / (1 + np.exp(-scaled))\n",
    "        weights = self.min_weight + (self.max_weight - self.min_weight) * sigmoid_output\n",
    "        weights = np.clip(weights, MIN_INVESTMENT, MAX_INVESTMENT)\n",
    "        return weights\n",
    "    \n",
    "    def optimize_across_windows(self, all_predictions, all_returns, all_rf_rates):\n",
    "        def objective(params):\n",
    "            sensitivity, max_w, min_w = params\n",
    "            if min_w >= max_w: return 1e9\n",
    "            \n",
    "            sharpes = []\n",
    "            for preds, rets, rfs in zip(all_predictions, all_returns, all_rf_rates):\n",
    "                scaled = preds * sensitivity\n",
    "                sigmoid_output = 1 / (1 + np.exp(-scaled))\n",
    "                weights = min_w + (max_w - min_w) * sigmoid_output\n",
    "                weights = np.clip(weights, MIN_INVESTMENT, MAX_INVESTMENT)\n",
    "                sharpe = calculate_sharpe_ratio(weights, rets, rfs)\n",
    "                sharpes.append(sharpe)\n",
    "            \n",
    "            score = np.mean(sharpes) - 0.5 * np.std(sharpes)\n",
    "            return -score\n",
    "\n",
    "        x0 = [1500, 1.3, 0.5] \n",
    "        bounds = [(500, 5000), (1.0, 2.0), (0.0, 1.0)]\n",
    "        result = minimize(objective, x0, method='Nelder-Mead', bounds=bounds, tol=1e-4)\n",
    "        \n",
    "        best_params = result.x\n",
    "        self.sensitivity = best_params[0]\n",
    "        self.max_weight = best_params[1]\n",
    "        self.min_weight = best_params[2]\n",
    "        \n",
    "        return self\n",
    "\n",
    "# ============================================\n",
    "# ENSEMBLE MODEL\n",
    "# ============================================\n",
    "class EnsembleModel:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        self.weights = []\n",
    "        \n",
    "    def _optimize_weights(self, predictions_list, y_true):\n",
    "        def objective(weights):\n",
    "            weights = np.array(weights)\n",
    "            weights = weights / np.sum(weights)\n",
    "            final_pred = np.zeros_like(predictions_list[0])\n",
    "            for i, w in enumerate(weights):\n",
    "                final_pred += w * predictions_list[i]\n",
    "            return -np.corrcoef(final_pred, y_true)[0, 1]\n",
    "\n",
    "        n_models = len(predictions_list)\n",
    "        init_weights = [1.0 / n_models] * n_models\n",
    "        constraints = ({'type': 'eq', 'fun': lambda w: 1 - np.sum(w)})\n",
    "        bounds = [(0, 1) for _ in range(n_models)]\n",
    "        \n",
    "        result = minimize(objective, init_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        return list(result.x / np.sum(result.x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        split_idx = int(len(X) * 0.8)\n",
    "        X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        if HAS_LGB:\n",
    "            models_configs = [\n",
    "                {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.03, 'num_leaves': 15,\n",
    "                 'min_child_samples': 60, 'reg_alpha': 0.2, 'reg_lambda': 0.2,\n",
    "                 'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': 42},\n",
    "                {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.04, 'num_leaves': 20,\n",
    "                 'min_child_samples': 50, 'reg_alpha': 0.15, 'reg_lambda': 0.15,\n",
    "                 'subsample': 0.75, 'colsample_bytree': 0.75, 'random_state': 123},\n",
    "                {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05, 'num_leaves': 25,\n",
    "                 'min_child_samples': 40, 'reg_alpha': 0.1, 'reg_lambda': 0.1,\n",
    "                 'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': 456},\n",
    "            ]\n",
    "            self.models = [lgb.LGBMRegressor(**config, verbose=-1) for config in models_configs]\n",
    "        else:\n",
    "            self.models = [\n",
    "                GradientBoostingRegressor(n_estimators=200, max_depth=4, learning_rate=0.05,\n",
    "                                         min_samples_leaf=40, random_state=42),\n",
    "                RandomForestRegressor(n_estimators=200, max_depth=6, min_samples_leaf=30,\n",
    "                                     random_state=42, n_jobs=-1),\n",
    "                Ridge(alpha=10.0)\n",
    "            ]\n",
    "        \n",
    "        for model in self.models:\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "        val_preds = [model.predict(X_val) for model in self.models]\n",
    "        self.weights = self._optimize_weights(val_preds, y_val)\n",
    "        \n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for model, weight in zip(self.models, self.weights):\n",
    "            predictions += weight * model.predict(X)\n",
    "        return predictions\n",
    "\n",
    "# ============================================\n",
    "# TRAINING\n",
    "# ============================================\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "target_cols = ['forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\n",
    "id_col = 'date_id'\n",
    "exclude_cols = [id_col] + target_cols\n",
    "\n",
    "test_df_sample = pd.read_csv(f'{DATA_DIR}/test.csv', nrows=5)\n",
    "test_cols = set(test_df_sample.columns)\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col not in exclude_cols and col in test_cols]\n",
    "\n",
    "# Filter training data\n",
    "missing_by_date = train_df[feature_cols].isnull().sum(axis=1)\n",
    "threshold = len(feature_cols) * 0.05\n",
    "valid_mask = missing_by_date <= threshold\n",
    "valid_start_idx = valid_mask.idxmax()\n",
    "valid_start_date = train_df.loc[valid_start_idx, 'date_id']\n",
    "train_clean = train_df[train_df['date_id'] >= valid_start_date].copy().reset_index(drop=True)\n",
    "\n",
    "# Multi-window cross-validation\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "all_predictions = []\n",
    "all_returns = []\n",
    "all_rf_rates = []\n",
    "\n",
    "for train_idx, val_idx in tscv.split(train_clean):\n",
    "    train_data = train_clean.iloc[train_idx].copy()\n",
    "    val_data = train_clean.iloc[val_idx].copy()\n",
    "    \n",
    "    fe_fold = FeatureEngineer()\n",
    "    X_train = fe_fold.fit_transform(train_data, feature_cols)\n",
    "    y_train = train_data['forward_returns'].values\n",
    "    \n",
    "    X_val = fe_fold.transform(val_data)\n",
    "    \n",
    "    model_fold = EnsembleModel()\n",
    "    model_fold.fit(X_train, y_train)\n",
    "    \n",
    "    val_preds = model_fold.predict(X_val)\n",
    "    \n",
    "    all_predictions.append(val_preds)\n",
    "    all_returns.append(val_data['forward_returns'].values)\n",
    "    all_rf_rates.append(val_data['risk_free_rate'].values)\n",
    "\n",
    "# Optimize strategy\n",
    "strategy = RobustStrategy()\n",
    "strategy.optimize_across_windows(all_predictions, all_returns, all_rf_rates)\n",
    "\n",
    "# Final training\n",
    "fe = FeatureEngineer()\n",
    "X_full = fe.fit_transform(train_clean, feature_cols)\n",
    "y_full = train_clean['forward_returns'].values\n",
    "\n",
    "model = EnsembleModel()\n",
    "model.fit(X_full, y_full)\n",
    "\n",
    "# ============================================\n",
    "# PREDICTION FUNCTION\n",
    "# ============================================\n",
    "def predict(test_batch: pl.DataFrame) -> pl.DataFrame:\n",
    "    test_pd = test_batch.to_pandas()\n",
    "    \n",
    "    if 'date_id' in test_pd.columns:\n",
    "        row_ids = test_pd['date_id'].values\n",
    "    else:\n",
    "        row_ids = test_pd.iloc[:, 0].values\n",
    "    \n",
    "    X_test = fe.transform(test_pd)\n",
    "    predictions = model.predict(X_test)\n",
    "    weights = strategy.predict_to_weight(predictions)\n",
    "    weights = np.clip(weights, MIN_INVESTMENT, MAX_INVESTMENT)\n",
    "    \n",
    "    result = pl.DataFrame({\n",
    "        'date_id': row_ids,\n",
    "        'prediction': weights\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ============================================\n",
    "# KAGGLE INFERENCE SERVER\n",
    "# ============================================\n",
    "import kaggle_evaluation.core.templates\n",
    "from kaggle_evaluation.default_gateway import DefaultGateway\n",
    "\n",
    "class HullTacticalInferenceServer(kaggle_evaluation.core.templates.InferenceServer):\n",
    "    def __init__(self):\n",
    "        super().__init__(predict)\n",
    "    \n",
    "    def _get_gateway_for_test(self, data_paths=None, file_share_dir=None):\n",
    "        return DefaultGateway(data_paths)\n",
    "\n",
    "# ============================================\n",
    "# RUN\n",
    "# ============================================\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server = HullTacticalInferenceServer()\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "    test_pl = pl.from_pandas(test_df)\n",
    "    submission = predict(test_pl)\n",
    "    submission_pd = submission.to_pandas()\n",
    "    \n",
    "    import pyarrow as pa\n",
    "    import pyarrow.parquet as pq\n",
    "    \n",
    "    table = pa.Table.from_pandas(submission_pd, preserve_index=False)\n",
    "    pq.write_table(table, 'submission.parquet')\n",
    "    submission_pd.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(f'Submission saved: {len(submission_pd)} predictions')\n",
    "    print(f'Weight range: [{submission_pd[\"prediction\"].min():.4f}, {submission_pd[\"prediction\"].max():.4f}]')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
