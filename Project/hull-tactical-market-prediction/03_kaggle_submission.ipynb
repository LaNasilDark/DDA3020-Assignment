{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85c18c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded!\n",
      "LightGBM available: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# HULL TACTICAL MARKET PREDICTION - KAGGLE SUBMISSION\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Try to import lightgbm (available on Kaggle)\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGB = True\n",
    "except ImportError:\n",
    "    HAS_LGB = False\n",
    "\n",
    "print('Libraries loaded!')\n",
    "print(f'LightGBM available: {HAS_LGB}')\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "MIN_INVESTMENT = 0\n",
    "MAX_INVESTMENT = 2\n",
    "\n",
    "# Data paths - adjust for Kaggle environment\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    DATA_DIR = '/kaggle/input/hull-tactical-market-prediction'\n",
    "else:\n",
    "    DATA_DIR = '.'\n",
    "\n",
    "print(f'Data directory: {DATA_DIR}')\n",
    "\n",
    "# ============================================\n",
    "# FEATURE ENGINEERING CLASS\n",
    "# ============================================\n",
    "class FeatureEngineer:\n",
    "    def __init__(self):\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_cols = None\n",
    "        \n",
    "    def fit(self, df, feature_cols):\n",
    "        self.feature_cols = feature_cols\n",
    "        X = df[feature_cols].values\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "        self.scaler.fit(X_imputed)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        X = df[self.feature_cols].values\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "        X_scaled = self.scaler.transform(X_imputed)\n",
    "        return X_scaled\n",
    "    \n",
    "    def fit_transform(self, df, feature_cols):\n",
    "        self.fit(df, feature_cols)\n",
    "        return self.transform(df)\n",
    "\n",
    "# ============================================\n",
    "# TRADING STRATEGY CLASS\n",
    "# ============================================\n",
    "class TradingStrategy:\n",
    "    def __init__(self, method='sigmoid', scale=100):\n",
    "        self.method = method\n",
    "        self.scale = scale\n",
    "        \n",
    "    def predict_to_weight(self, predictions):\n",
    "        if self.method == 'sigmoid':\n",
    "            weights = 2 / (1 + np.exp(-self.scale * predictions))\n",
    "        elif self.method == 'threshold':\n",
    "            weights = np.where(predictions > 0, 1.5, 0.5)\n",
    "        else:\n",
    "            weights = np.ones_like(predictions)\n",
    "        \n",
    "        return np.clip(weights, MIN_INVESTMENT, MAX_INVESTMENT)\n",
    "\n",
    "# ============================================\n",
    "# MODEL TRAINING AND PREPARATION\n",
    "# ============================================\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "\n",
    "# Define feature columns\n",
    "target_cols = ['forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\n",
    "id_col = 'date_id'\n",
    "exclude_cols = [id_col] + target_cols\n",
    "\n",
    "# Get test columns to ensure we only use features available in test set\n",
    "test_df_sample = pd.read_csv(f'{DATA_DIR}/test.csv', nrows=5)\n",
    "test_cols = set(test_df_sample.columns)\n",
    "\n",
    "# Feature columns: must be in both train and test, and not excluded\n",
    "feature_cols = [col for col in train_df.columns \n",
    "                if col not in exclude_cols and col in test_cols]\n",
    "print(f'Number of features: {len(feature_cols)}')\n",
    "\n",
    "# Filter training data - use only complete data\n",
    "missing_by_date = train_df[feature_cols].isnull().sum(axis=1)\n",
    "threshold = len(feature_cols) * 0.05\n",
    "valid_mask = missing_by_date <= threshold\n",
    "valid_start_idx = valid_mask.idxmax()\n",
    "valid_start_date = train_df.loc[valid_start_idx, 'date_id']\n",
    "train_clean = train_df[train_df['date_id'] >= valid_start_date].copy().reset_index(drop=True)\n",
    "print(f'Training samples after filtering: {len(train_clean)}')\n",
    "\n",
    "# Prepare feature engineering\n",
    "fe = FeatureEngineer()\n",
    "X_train = fe.fit_transform(train_clean, feature_cols)\n",
    "y_train = train_clean['forward_returns'].values\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "\n",
    "# Train model\n",
    "if HAS_LGB:\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "else:\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Model trained!')\n",
    "\n",
    "# Initialize trading strategy\n",
    "strategy = TradingStrategy(method='sigmoid', scale=100)\n",
    "\n",
    "# ============================================\n",
    "# PREDICTION FUNCTION FOR KAGGLE API\n",
    "# ============================================\n",
    "\n",
    "def predict(test_batch: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Make predictions for a batch of test data.\n",
    "    This function is called by Kaggle's evaluation API.\n",
    "    \"\"\"\n",
    "    # Convert polars to pandas for processing\n",
    "    test_pd = test_batch.to_pandas()\n",
    "    \n",
    "    # Get the row ID column (usually 'date_id')\n",
    "    if 'date_id' in test_pd.columns:\n",
    "        row_ids = test_pd['date_id'].values\n",
    "    else:\n",
    "        row_ids = test_pd.iloc[:, 0].values\n",
    "    \n",
    "    # Prepare features - only use columns that were in training\n",
    "    X_test = fe.transform(test_pd)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Convert to trading weights\n",
    "    weights = strategy.predict_to_weight(predictions)\n",
    "    \n",
    "    # Ensure weights are within valid range [0, 2]\n",
    "    weights = np.clip(weights, MIN_INVESTMENT, MAX_INVESTMENT)\n",
    "    \n",
    "    # Create result DataFrame\n",
    "    result = pl.DataFrame({\n",
    "        'date_id': row_ids,\n",
    "        'prediction': weights\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "print('Predict function defined!')\n",
    "\n",
    "# ============================================\n",
    "# KAGGLE SUBMISSION - INFERENCE SERVER SETUP\n",
    "# ============================================\n",
    "\n",
    "import kaggle_evaluation.core.templates\n",
    "from kaggle_evaluation.default_gateway import DefaultGateway\n",
    "\n",
    "class HullTacticalInferenceServer(kaggle_evaluation.core.templates.InferenceServer):\n",
    "    \"\"\"Custom inference server that wraps our predict function.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(predict)\n",
    "    \n",
    "    def _get_gateway_for_test(self, data_paths=None, file_share_dir=None):\n",
    "        return DefaultGateway(data_paths)\n",
    "\n",
    "# ============================================\n",
    "# RUN INFERENCE SERVER / LOCAL TEST\n",
    "# ============================================\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # KAGGLE COMPETITION MODE\n",
    "    print('Running in Kaggle competition mode...')\n",
    "    inference_server = HullTacticalInferenceServer()\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # LOCAL TESTING MODE\n",
    "    print('Running in local testing mode...')\n",
    "    \n",
    "    # Load test data and make predictions\n",
    "    test_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "    test_pl = pl.from_pandas(test_df)\n",
    "    \n",
    "    print(f'Test data shape: {test_df.shape}')\n",
    "    \n",
    "    # Make predictions using our predict function\n",
    "    submission = predict(test_pl)\n",
    "    submission_pd = submission.to_pandas()\n",
    "    \n",
    "    # Save submission files\n",
    "    import pyarrow as pa\n",
    "    import pyarrow.parquet as pq\n",
    "    \n",
    "    # Save as parquet (Kaggle format)\n",
    "    table = pa.Table.from_pandas(submission_pd, preserve_index=False)\n",
    "    pq.write_table(table, 'submission.parquet')\n",
    "    \n",
    "    # Save as CSV (for reference)\n",
    "    submission_pd.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(f'\\nâœ“ Submission saved!')\n",
    "    print(f'  Total predictions: {len(submission_pd)}')\n",
    "    print(f'  Weight range: [{submission_pd[\"prediction\"].min():.4f}, {submission_pd[\"prediction\"].max():.4f}]')\n",
    "    print(f'  Mean weight: {submission_pd[\"prediction\"].mean():.4f}')\n",
    "    print(f'\\nAll predictions:')\n",
    "    print(submission_pd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
